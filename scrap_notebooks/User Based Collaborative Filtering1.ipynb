{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. \"Users who are similar to you also liked these courses.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "courses_df = pd.read_csv('../data/Coursera_courses.csv').drop_duplicates()\n",
    "reviews_df = pd.read_csv('../data/Coursera_reviews.csv').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name           0\n",
      "institution    0\n",
      "course_url     0\n",
      "course_id      0\n",
      "dtype: int64\n",
      "reviews         56\n",
      "reviewers        0\n",
      "date_reviews     0\n",
      "rating           0\n",
      "course_id        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reviews_df['date_reviews'] = pd.to_datetime(reviews_df['date_reviews'])\n",
    "\n",
    "# Sort reviews by date\n",
    "reviews_df = reviews_df.sort_values(by='date_reviews')\n",
    "\n",
    "print(courses_df.isnull().sum())\n",
    "print(reviews_df.isnull().sum())\n",
    "courses_df = courses_df.drop_duplicates(subset='course_id')\n",
    "reviews_df = reviews_df.drop_duplicates(subset=['reviewers', 'course_id'])\n",
    "\n",
    "# Define a cutoff date for splitting the data (e.g., the last 20% of dates)\n",
    "cutoff_date = reviews_df['date_reviews'].quantile(0.8)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = reviews_df[reviews_df['date_reviews'] < cutoff_date]\n",
    "test_data = reviews_df[reviews_df['date_reviews'] >= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 604 features, but NearestNeighbors is expecting 287808 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jerem/comp9727-project/notebooks/User Based Collaborative Filtering.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m f1_scores \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m test_interaction_matrix_structure\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     predicted_courses \u001b[39m=\u001b[39m get_user_predictions(user_id, full_interaction_matrix, model_knn)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     user_f1_score \u001b[39m=\u001b[39m evaluate_predictions(test_interaction_matrix_structure[user_id], predicted_courses)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     f1_scores\u001b[39m.\u001b[39mappend(user_f1_score)\n",
      "\u001b[1;32m/home/jerem/comp9727-project/notebooks/User Based Collaborative Filtering.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m user_index \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(train_interaction_matrix\u001b[39m.\u001b[39mcolumns)\u001b[39m.\u001b[39mindex(user_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m user_vector \u001b[39m=\u001b[39m train_interaction_matrix_sparse[:, user_index]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m distances, indices \u001b[39m=\u001b[39m model_knn\u001b[39m.\u001b[39;49mkneighbors(user_vector\u001b[39m.\u001b[39;49mT, n_neighbors\u001b[39m=\u001b[39;49mn_recommendations\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# We add +1 because the user's own interaction is included in the neighbors\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# We start from 1 to exclude the user's own interaction\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jerem/comp9727-project/notebooks/User%20Based%20Collaborative%20Filtering.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m similar_users_indices \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mflatten()[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/neighbors/_base.py:806\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    804\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    805\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 806\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    808\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[1;32m    809\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 604 features, but NearestNeighbors is expecting 287808 features as input."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "all_courses = pd.concat([train_data['course_id'], test_data['course_id']]).unique()\n",
    "all_reviewers = pd.concat([train_data['reviewers'], test_data['reviewers']]).unique()\n",
    "\n",
    "full_interaction_matrix = pd.DataFrame(0, index=all_courses, columns=all_reviewers)\n",
    "\n",
    "for _, row in train_data.iterrows():\n",
    "    full_interaction_matrix.at[row['course_id'], row['reviewers']] = row['rating']\n",
    "\n",
    "test_interaction_matrix_structure = full_interaction_matrix.copy()\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    test_interaction_matrix_structure.at[row['course_id'], row['reviewers']] = row['rating']\n",
    "\n",
    "train_interaction_matrix_sparse = csr_matrix(full_interaction_matrix.values)\n",
    "test_interaction_matrix_sparse = csr_matrix(test_interaction_matrix_structure.values)\n",
    "\n",
    "# Train\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "model_knn.fit(train_interaction_matrix_sparse)\n",
    "\n",
    "# Prediction and evaluation\n",
    "def get_user_predictions(user_id, train_interaction_matrix, model_knn, n_recommendations=5):\n",
    "    user_index = list(train_interaction_matrix.columns).index(user_id)\n",
    "    user_vector = train_interaction_matrix_sparse[:, user_index]\n",
    "    distances, indices = model_knn.kneighbors(user_vector.T, n_neighbors=n_recommendations+1)\n",
    "    \n",
    "    # (exclude the user's own interaction)\n",
    "    similar_users_indices = indices.flatten()[1:]\n",
    "    similar_users = train_interaction_matrix.columns[similar_users_indices]\n",
    "    \n",
    "    # Aggregate the courses of similar users and count the frequency of courses\n",
    "    course_frequencies = full_interaction_matrix[similar_users].sum(axis=1)\n",
    "    recommended_courses = course_frequencies.sort_values(ascending=False).head(n_recommendations).index.tolist()\n",
    "    \n",
    "    return set(recommended_courses)\n",
    "\n",
    "def evaluate_predictions(test_interaction_matrix, predicted_courses, threshold=4):\n",
    "    actual_relevant_courses = set(test_interaction_matrix.index[test_interaction_matrix >= threshold])\n",
    "    predicted_relevant_courses = predicted_courses\n",
    "\n",
    "    tp = len(actual_relevant_courses & predicted_relevant_courses)\n",
    "    fp = len(predicted_relevant_courses - actual_relevant_courses)\n",
    "    fn = len(actual_relevant_courses - predicted_relevant_courses)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Iterate over users in the test set to get recommendations and evaluate the F1 score\n",
    "f1_scores = []\n",
    "for user_id in test_interaction_matrix_structure.columns:\n",
    "    predicted_courses = get_user_predictions(user_id, full_interaction_matrix, model_knn)\n",
    "    user_f1_score = evaluate_predictions(test_interaction_matrix_structure[user_id], predicted_courses)\n",
    "    f1_scores.append(user_f1_score)\n",
    "\n",
    "# Calculate the mean F1 score across all users\n",
    "mean_f1_score = np.mean(f1_scores)\n",
    "print(f\"Mean F1 Score: {mean_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
