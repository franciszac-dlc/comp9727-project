{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import time\n",
    "wd = %pwd\n",
    "if wd.split('\\\\')[-1] == 'notebooks':\n",
    "    %cd ..\n",
    "\n",
    "from coursemate.dataset import Dataset\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Coursera courses...\n",
      "Loading Coursera reviews...\n",
      "Segmenting out students with less than 3 or more than 50 reviews...\n",
      "Setting the train-test split by rating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174219it [00:11, 15441.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the training and test rating matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128771it [00:08, 14669.52it/s]\n",
      "45448it [00:03, 14214.80it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset('data/Coursera_courses.csv', 'data/Coursera.csv', 'data/Coursera_reviews.csv')\n",
    "dataset.set_interaction_counts(3, 50)\n",
    "dataset.set_train_test_split_by_ratings()\n",
    "training_matrix, test_matrix = dataset.get_train_test_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset.train_ratings.merge(dataset.df_courses, how='left',on='course_id')\n",
    "test_df = dataset.test_ratings.merge(dataset.df_courses, how='left',on='course_id')\n",
    "users = dataset.student_set.copy(deep=True)\n",
    "courses = dataset.course_set.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128771 45448\n",
      "30719 30719\n",
      "30719 468\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(test_df))\n",
    "print(len(pd.unique(train_df['reviewers'])),len(pd.unique(test_df['reviewers'])))\n",
    "print(len(users), len(courses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_skills(skill_text):\n",
    "    skills = set(skill_text.replace(')','').replace('(','').replace('-',' ').lower().split())\n",
    "    return ' '.join(skills)\n",
    "\n",
    "def process_description(description):\n",
    "    description = description.lower()\n",
    "    description = re.sub(r'[^\\w\\s]', '', description)\n",
    "    tokens = word_tokenize(description)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    #tokens = [ps.stem(word) for word in tokens]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def process_reviewers(reviewer):\n",
    "    reviewer = reviewer.lower()\n",
    "    reviewer = re.sub(r'[^\\w\\s]', '', reviewer).replace('by ', '').strip()\n",
    "    return reviewer\n",
    "\n",
    "train_df['reviewers'] = train_df['reviewers'].apply(process_reviewers)\n",
    "test_df['reviewers'] = test_df['reviewers'].apply(process_reviewers)\n",
    "\n",
    "train_df['skills'] = train_df['skills'].apply(process_skills)\n",
    "test_df['skills'] = test_df['skills'].apply(process_skills)\n",
    "\n",
    "train_df['description'] = train_df['description'].apply(process_description)\n",
    "test_df['description'] = test_df['description'].apply(process_description)\n",
    "\n",
    "courses['description'] = courses['description'].apply(process_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(user_id,n_recommendations,vectorizer,course_vectors,category):\n",
    "    user_reviews = train_df[train_df['reviewers'] == user_id][category]\n",
    "    user_vector = vectorizer.transform(user_reviews)\n",
    "\n",
    "    most_similar_courses = find_most_similar_courses(user_vector,course_vectors,user_reviews,category)[:n_recommendations]\n",
    "    \n",
    "    recommended_courses = []\n",
    "    for course_id, similarity in most_similar_courses:\n",
    "        recommended_courses.append(course_id)\n",
    "\n",
    "    return recommended_courses\n",
    "\n",
    "\n",
    "def find_most_similar_courses(user_vector,course_vectors,user_reviewed_courses,category):   \n",
    "    most_similar_courses = []\n",
    "    for other_course_id in courses.index:\n",
    "        if other_course_id in user_reviewed_courses:\n",
    "            continue\n",
    "\n",
    "        desc = courses[courses.index == other_course_id][category]\n",
    "        if desc.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        desc = desc.iloc[0]\n",
    "        course_vector = course_vectors[other_course_id]\n",
    "        normalized_user_vector = normalize(user_vector)\n",
    "        normalized_course_vector = normalize(course_vector)\n",
    "        similarity = cosine_similarity(normalized_user_vector, normalized_course_vector)\n",
    "        #similarity = cosine_similarity(user_vector, course_vector)\n",
    "        most_similar_courses.append((other_course_id, similarity.mean()))\n",
    "        \n",
    "    most_similar_courses.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return most_similar_courses\n",
    "\n",
    "def evaluate_model(n_users,n_recommendations, Vectorizer,n_features, category):\n",
    "    grouped_df = train_df.groupby('reviewers')['course_id'].count()\n",
    "    filtered_df = grouped_df[grouped_df > 3]\n",
    "    users = filtered_df.index[:n_users]\n",
    "\n",
    "    vectorizer = Vectorizer(max_features=n_features)\n",
    "    vectorizer.fit(courses[category])\n",
    "    \n",
    "    course_vectors = {}\n",
    "    for id,row in courses.iterrows():\n",
    "        course_vectors[id] = vectorizer.transform([row[category]])\n",
    "    \n",
    "            \n",
    "    hitrate,f1,recall,precision,count = 0,0,0,0,0\n",
    "    for user_id in users:\n",
    "        recommendations = make_recommendations(user_id,n_recommendations,vectorizer,course_vectors,category)\n",
    "\n",
    "        # For metric calculating\n",
    "        user_reviewed_courses = test_df[test_df['reviewers'] == user_id]['course_id'].unique()\n",
    "        res = len(set(user_reviewed_courses) & set(recommendations))\n",
    "\n",
    "        if res > 0:\n",
    "            hitrate += 1\n",
    "\n",
    "        all_courses = np.concatenate((recommendations, user_reviewed_courses))\n",
    "        recommended_vector = [1 if course in recommendations else 0 for course in all_courses]\n",
    "        taken_vector = [1 if course in user_reviewed_courses else 0 for course in all_courses]\n",
    "\n",
    "        # Calculate Metrics\n",
    "        f1 += f1_score(taken_vector, recommended_vector)\n",
    "        precision += precision_score(taken_vector, recommended_vector)\n",
    "        recall += recall_score(taken_vector, recommended_vector)\n",
    "\n",
    "        count +=1\n",
    "    #print(f\"Vectorizer: {Vectorizer.__name__} Features: {n}, category: {category}\")\n",
    "    #print(f\"Hit-rate: {(hitrate / count):.3f}, F1: {(f1 / count):.3f}, Precision: {(precision / count):.3f}, Recall: {(recall / count):.3f}\")\n",
    "    return hitrate / count, f1 / count\n",
    "\n",
    "# Testable parameters\n",
    "how_many_users_to_test = 30\n",
    "vectorizers = [TfidfVectorizer]\n",
    "n_recommendations_list = [5, 10,15]\n",
    "n_features_list = [1000,10000,100000]\n",
    "categories = ['skills', 'description']\n",
    "\n",
    "\n",
    "best_params_hitrate = {}\n",
    "best_params_f1 = {}\n",
    "\n",
    "# Initialize dictionaries to keep track of the highest scores for each n_recommendations\n",
    "highest_hitrate = {}\n",
    "highest_f1 = {}\n",
    "\n",
    "\n",
    "\n",
    "# Gridsearch\n",
    "# Test all combinations of parameters\n",
    "for n_recommendations in n_recommendations_list:\n",
    "    # Initialize the highest scores for this n_recommendations\n",
    "    highest_hitrate[n_recommendations] = 0\n",
    "    highest_f1[n_recommendations] = 0\n",
    "\n",
    "    for vectorizer in vectorizers:\n",
    "        for n_features in n_features_list:\n",
    "            for category in categories:\n",
    "                hitrate, f1 = evaluate_model(how_many_users_to_test, n_recommendations, vectorizer, n_features, category)\n",
    "\n",
    "                # Update the best parameters for hitrate\n",
    "                if hitrate > highest_hitrate[n_recommendations]:\n",
    "                    highest_hitrate[n_recommendations] = hitrate\n",
    "                    best_params_hitrate[n_recommendations] = (vectorizer, n_features, category)\n",
    "\n",
    "                # Update the best parameters for f1 score\n",
    "                if f1 > highest_f1[n_recommendations]:\n",
    "                    highest_f1[n_recommendations] = f1\n",
    "                    best_params_f1[n_recommendations] = (vectorizer, n_features, category)\n",
    "\n",
    "    # Print the best parameters for this n_recommendations\n",
    "    print(f\"For n_recommendations = {n_recommendations}:\")\n",
    "    print(f\"Hitrate: {highest_hitrate[n_recommendations]}, f1-score: {highest_f1[n_recommendations]}\")\n",
    "    print(f\"Best parameters for highest hitrate: Vectorizer = {best_params_hitrate[n_recommendations][0].__name__}, n_features = {best_params_hitrate[n_recommendations][1]}, category = {best_params_hitrate[n_recommendations][2]}\")\n",
    "    print(f\"Best parameters for highest f1 score: Vectorizer = {best_params_f1[n_recommendations][0].__name__}, n_features = {best_params_f1[n_recommendations][1]}, category = {best_params_f1[n_recommendations][2]}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Development\\School-UNSW\\COMP9727\\project\\comp9727-project\\notebooks\\content-based-rec.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Features: \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m, duration: \u001b[39m\u001b[39m{\u001b[39;00m(time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart_time)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHit-rate: \u001b[39m\u001b[39m{\u001b[39;00m(hitrate\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mcount)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, F1: \u001b[39m\u001b[39m{\u001b[39;00m(f1\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mcount)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Precision: \u001b[39m\u001b[39m{\u001b[39;00m(precision\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mcount)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Recall: \u001b[39m\u001b[39m{\u001b[39;00m(recall\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mcount)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m evaluate_model(\u001b[39m30\u001b[39;49m, \u001b[39m10\u001b[39;49m, Doc2Vec, \u001b[39m10000\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Development\\School-UNSW\\COMP9727\\project\\comp9727-project\\notebooks\\content-based-rec.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m hitrate, f1, recall, precision, count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m user_id \u001b[39min\u001b[39;00m users:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     recommendations \u001b[39m=\u001b[39m make_recommendations(user_id, n_recommendations, model, course_vectors, category)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m# For metric calculating\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     user_reviewed_courses \u001b[39m=\u001b[39m test_df[test_df[\u001b[39m'\u001b[39m\u001b[39mreviewers\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m user_id][\u001b[39m'\u001b[39m\u001b[39mcourse_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n",
      "\u001b[1;32mc:\\Development\\School-UNSW\\COMP9727\\project\\comp9727-project\\notebooks\\content-based-rec.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m user_vector \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minfer_vector(user_reviews)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#print(train_df[train_df['reviewers'] == user_id]['course_id'].unique())\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m most_similar_courses \u001b[39m=\u001b[39m find_most_similar_courses(user_vector, course_vectors, user_reviews,category)[:n_recommendations]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m recommended_courses \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m course_id, similarity \u001b[39min\u001b[39;00m most_similar_courses:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m#print(course_id)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Development\\School-UNSW\\COMP9727\\project\\comp9727-project\\notebooks\\content-based-rec.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m course_vector \u001b[39m=\u001b[39m course_vectors[other_course_id]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m normalized_user_vector \u001b[39m=\u001b[39m normalize(user_vector)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m normalized_course_vector \u001b[39m=\u001b[39m normalize(course_vector)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m similarity \u001b[39m=\u001b[39m cosine_similarity(normalized_user_vector, normalized_course_vector)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Development/School-UNSW/COMP9727/project/comp9727-project/notebooks/content-based-rec.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#similarity = cosine_similarity(user_vector, course_vector)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1841\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1838\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# axis == 1:\u001b[39;00m\n\u001b[0;32m   1839\u001b[0m     sparse_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1841\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1842\u001b[0m     X,\n\u001b[0;32m   1843\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49msparse_format,\n\u001b[0;32m   1844\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1845\u001b[0m     estimator\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthe normalize function\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1846\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m   1847\u001b[0m )\n\u001b[0;32m   1848\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1849\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[0;32m    958\u001b[0m             array,\n\u001b[0;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:118\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# error message.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(over\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 118\u001b[0m     first_pass_isfinite \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39misfinite(xp\u001b[39m.\u001b[39;49msum(X))\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2295\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   2296\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m-> 2298\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   2299\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\Timia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "def make_recommendations(user_id, n_recommendations, model, course_vectors,category):\n",
    "    user_reviews = train_df[train_df['reviewers'] == user_id][category]\n",
    "    user_vector = model.infer_vector(user_reviews).reshape(1, -1)\n",
    "\n",
    "    #print(train_df[train_df['reviewers'] == user_id]['course_id'].unique())\n",
    "    most_similar_courses = find_most_similar_courses(user_vector, course_vectors, user_reviews,category)[:n_recommendations]\n",
    "    \n",
    "    recommended_courses = []\n",
    "    for course_id, similarity in most_similar_courses:\n",
    "        #print(course_id)\n",
    "        recommended_courses.append(course_id)\n",
    "\n",
    "    #print('\\n\\n')\n",
    "\n",
    "    return recommended_courses\n",
    "\n",
    "def find_most_similar_courses(user_vector, course_vectors, user_reviewed_courses,category):   \n",
    "    most_similar_courses = []\n",
    "    for other_course_id in courses.index:\n",
    "        if other_course_id in user_reviewed_courses:\n",
    "            continue\n",
    "\n",
    "        desc = train_df[train_df['course_id'] == other_course_id][category]\n",
    "        if desc.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        desc = desc.iloc[0]\n",
    "        course_vector = course_vectors[other_course_id].reshape(1, -1)\n",
    "\n",
    "        normalized_user_vector = normalize(user_vector)\n",
    "        normalized_course_vector = normalize(course_vector)\n",
    "        similarity = cosine_similarity(normalized_user_vector, normalized_course_vector)\n",
    "        #similarity = cosine_similarity(user_vector, course_vector)\n",
    "        most_similar_courses.append((other_course_id, similarity[0]))\n",
    "        \n",
    "    most_similar_courses.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return most_similar_courses\n",
    "\n",
    "def evaluate_model(n_users, n_recommendations, vectorizer_model, n_features, category):\n",
    "    grouped_df = train_df.groupby('reviewers')['course_id'].count()\n",
    "    filtered_df = grouped_df[grouped_df > 3]\n",
    "    users = filtered_df.index[:n_users]      \n",
    "    start_time = time.time()\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(courses[category].tolist())]\n",
    "\n",
    "    model = vectorizer_model(documents, dm=1, vector_size=n_features, epochs=250)    \n",
    "    vectors = [model.infer_vector(word_tokenize(doc.lower())) for doc in courses['description'].tolist()]\n",
    "\n",
    "    course_vectors = {}\n",
    "    for i, row in enumerate(courses.iterrows()):\n",
    "        course_vectors[row[0]] = vectors[i]\n",
    "\n",
    "    hitrate, f1, recall, precision, count = 0, 0, 0, 0, 0\n",
    "    for user_id in users:\n",
    "        recommendations = make_recommendations(user_id, n_recommendations, model, course_vectors, category)\n",
    "\n",
    "        # For metric calculating\n",
    "        user_reviewed_courses = test_df[test_df['reviewers'] == user_id]['course_id'].unique()\n",
    "        res = len(set(user_reviewed_courses) & set(recommendations))\n",
    "\n",
    "        if res > 0:\n",
    "            hitrate += 1\n",
    "\n",
    "        all_courses = np.concatenate((recommendations, user_reviewed_courses))\n",
    "        recommended_vector = [1 if course in recommendations else 0 for course in all_courses]\n",
    "        taken_vector = [1 if course in user_reviewed_courses else 0 for course in all_courses]\n",
    "\n",
    "        # Calculate Metrics\n",
    "        f1 += f1_score(taken_vector, recommended_vector)\n",
    "        precision += precision_score(taken_vector, recommended_vector)\n",
    "        recall += recall_score(taken_vector, recommended_vector)\n",
    "\n",
    "        count +=1\n",
    "    print(f\"Model: {model.__class__.__name__} Features: {n_features}, duration: {(time.time()-start_time):.3f}\")\n",
    "    print(f\"Hit-rate: {(hitrate / count):.3f}, F1: {(f1 / count):.3f}, Precision: {(precision / count):.3f}, Recall: {(recall / count):.3f}\")\n",
    "evaluate_model(30, 10, Doc2Vec, 10000, 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: paraphrase-distilroberta-base-v1 Features: 100000\n",
      "Hit-rate: 0.100, F1: 0.041, Precision: 0.028, Recall: 0.077\n",
      "Model: paraphrase-multilingual-MiniLM-L12-v2 Features: 100000\n",
      "Hit-rate: 0.100, F1: 0.034, Precision: 0.023, Recall: 0.062\n",
      "Model: distiluse-base-multilingual-cased-v2 Features: 100000\n",
      "Hit-rate: 0.100, F1: 0.035, Precision: 0.023, Recall: 0.071\n",
      "Model: all-mpnet-base-v2 Features: 100000\n",
      "Hit-rate: 0.067, F1: 0.032, Precision: 0.022, Recall: 0.060\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def make_recommendations(user_id, n_recommendations, model, course_vectors, category):\n",
    "    user_reviews = train_df[train_df['reviewers'] == user_id][category]\n",
    "    user_vector = model.encode(user_reviews.tolist())\n",
    "\n",
    "    most_similar_courses = find_most_similar_courses(user_vector, course_vectors, user_reviews, category)[:n_recommendations]\n",
    "\n",
    "    recommended_courses = [course_id for course_id, _ in most_similar_courses]\n",
    "\n",
    "    return recommended_courses\n",
    "\n",
    "\n",
    "def find_most_similar_courses(user_vector, course_vectors, user_reviewed_courses, category):\n",
    "    most_similar_courses = []\n",
    "    for other_course_id in courses.index:\n",
    "        if other_course_id in user_reviewed_courses:\n",
    "            continue\n",
    "\n",
    "        desc = train_df[train_df['course_id'] == other_course_id][category]\n",
    "        if desc.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        desc = desc.iloc[0]\n",
    "        course_vector = course_vectors[other_course_id]  # Use precomputed vectors\n",
    "        similarity = cosine_similarity(user_vector, [course_vector])[0][0]  # Remove the extra list\n",
    "        most_similar_courses.append((other_course_id, similarity))\n",
    "\n",
    "    most_similar_courses.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return most_similar_courses\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(n_users, n_recommendations, model_name, category):\n",
    "    grouped_df = train_df.groupby('reviewers')['course_id'].count()\n",
    "    filtered_df = grouped_df[grouped_df > 3]\n",
    "    users = filtered_df.index[:n_users]\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "    course_vectors = {}\n",
    "    for id, row in courses.iterrows():\n",
    "        course_vectors[id] = model.encode([row[category]])[0]\n",
    "\n",
    "    hitrate, f1, recall, precision, count = 0, 0, 0, 0, 0\n",
    "    for user_id in users:\n",
    "        recommendations = make_recommendations(user_id, n_recommendations, model, course_vectors, category)\n",
    "\n",
    "        # For metric calculating\n",
    "        user_reviewed_courses = test_df[test_df['reviewers'] == user_id]['course_id'].unique()\n",
    "        res = len(set(user_reviewed_courses) & set(recommendations))\n",
    "\n",
    "        if res > 0:\n",
    "            hitrate += 1\n",
    "\n",
    "        all_courses = np.concatenate((recommendations, user_reviewed_courses))\n",
    "        recommended_vector = [1 if course in recommendations else 0 for course in all_courses]\n",
    "        taken_vector = [1 if course in user_reviewed_courses else 0 for course in all_courses]\n",
    "\n",
    "        # Calculate Metrics\n",
    "        f1 += f1_score(taken_vector, recommended_vector)\n",
    "        precision += precision_score(taken_vector, recommended_vector)\n",
    "        recall += recall_score(taken_vector, recommended_vector)\n",
    "\n",
    "        count +=1\n",
    "    print(f\"Model: {model_name} Features: {n_features}\")\n",
    "    print(f\"Hit-rate: {(hitrate / count):.3f}, F1: {(f1 / count):.3f}, Precision: {(precision / count):.3f}, Recall: {(recall / count):.3f}\")\n",
    "\n",
    "\n",
    "evaluate_model(30, 5, 'paraphrase-distilroberta-base-v1','description')\n",
    "evaluate_model(30, 5, 'paraphrase-multilingual-MiniLM-L12-v2','description')\n",
    "evaluate_model(30, 5, 'distiluse-base-multilingual-cased-v2','description')\n",
    "evaluate_model(30, 5, 'all-mpnet-base-v2','description')\n",
    "\n",
    "evaluate_model(30, 5, 'paraphrase-distilroberta-base-v1','skills')\n",
    "evaluate_model(30, 5, 'paraphrase-multilingual-MiniLM-L12-v2','skills')\n",
    "evaluate_model(30, 5, 'distiluse-base-multilingual-cased-v2','skills')\n",
    "evaluate_model(30, 5, 'all-mpnet-base-v2','skills')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_recommendations = 5:\n",
      "Hitrate: 0.26, f1-score: 0.11368919968919969\n",
      "Best parameters for highest hitrate: Vectorizer = TfidfVectorizer, n_features = 10000\n",
      "Best parameters for highest f1 score: Vectorizer = TfidfVectorizer, n_features = 10000\n",
      "\n",
      "\n",
      "For n_recommendations = 10:\n",
      "Hitrate: 0.42, f1-score: 0.12718724412842058\n",
      "Best parameters for highest hitrate: Vectorizer = TfidfVectorizer, n_features = 10000\n",
      "Best parameters for highest f1 score: Vectorizer = TfidfVectorizer, n_features = 10000\n",
      "\n",
      "\n",
      "For n_recommendations = 15:\n",
      "Hitrate: 0.5, f1-score: 0.12378236032972875\n",
      "Best parameters for highest hitrate: Vectorizer = TfidfVectorizer, n_features = 10000\n",
      "Best parameters for highest f1 score: Vectorizer = TfidfVectorizer, n_features = 10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mixing the \n",
    "def make_recommendations(user_id,n_recommendations,vectorizer,course_vectors):\n",
    "    user_reviews_skills = train_df[train_df['reviewers'] == user_id]['skills']\n",
    "    user_reviews_description = train_df[train_df['reviewers'] == user_id]['description']\n",
    "    user_reviews_combined = user_reviews_skills + ' ' + user_reviews_description\n",
    "    user_vector = vectorizer.transform(user_reviews_combined)\n",
    "\n",
    "    most_similar_courses = find_most_similar_courses(user_vector,course_vectors,user_reviews_combined)[:n_recommendations]\n",
    "    \n",
    "    recommended_courses = []\n",
    "    for course_id, similarity in most_similar_courses:\n",
    "        recommended_courses.append(course_id)\n",
    "\n",
    "    return recommended_courses\n",
    "\n",
    "\n",
    "def find_most_similar_courses(user_vector,course_vectors,user_reviewed_courses):   \n",
    "    most_similar_courses = []\n",
    "    for other_course_id in courses.index:\n",
    "        if other_course_id in user_reviewed_courses:\n",
    "            continue\n",
    "\n",
    "        course_vector = course_vectors[other_course_id]\n",
    "        normalized_user_vector = normalize(user_vector)\n",
    "        normalized_course_vector = normalize(course_vector)\n",
    "        similarity = cosine_similarity(normalized_user_vector, normalized_course_vector)\n",
    "        #similarity = cosine_similarity(user_vector, course_vector)\n",
    "        most_similar_courses.append((other_course_id, similarity.mean()))\n",
    "        \n",
    "    most_similar_courses.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return most_similar_courses\n",
    "\n",
    "def evaluate_model(n_users,n_recommendations, Vectorizer,n_features, category):\n",
    "    grouped_df = train_df.groupby('reviewers')['course_id'].count()\n",
    "    filtered_df = grouped_df[grouped_df > 3]\n",
    "    users = filtered_df.index[:n_users]\n",
    "\n",
    "    vectorizer = Vectorizer(max_features=n_features)\n",
    "    vectorizer.fit(courses['description']+courses['skills'])\n",
    "    \n",
    "    course_vectors = {}\n",
    "    for id,row in courses.iterrows():\n",
    "        course_vectors[id] = vectorizer.transform([row['description'] + row['skills']])\n",
    "    \n",
    "\n",
    "    hitrate,f1,recall,precision,count = 0,0,0,0,0\n",
    "    for user_id in users:\n",
    "        recommendations = make_recommendations(user_id,n_recommendations,vectorizer,course_vectors)\n",
    "\n",
    "        # For metric calculating\n",
    "        user_reviewed_courses = test_df[test_df['reviewers'] == user_id]['course_id'].unique()\n",
    "        res = len(set(user_reviewed_courses) & set(recommendations))\n",
    "\n",
    "        if res > 0:\n",
    "            hitrate += 1\n",
    "\n",
    "        all_courses = np.concatenate((recommendations, user_reviewed_courses))\n",
    "        recommended_vector = [1 if course in recommendations else 0 for course in all_courses]\n",
    "        taken_vector = [1 if course in user_reviewed_courses else 0 for course in all_courses]\n",
    "\n",
    "        # Calculate Metrics\n",
    "        f1 += f1_score(taken_vector, recommended_vector)\n",
    "        precision += precision_score(taken_vector, recommended_vector)\n",
    "\n",
    "        count +=1\n",
    "\n",
    "    return hitrate / count, f1 / count\n",
    "\n",
    "# Testable parameters\n",
    "how_many_users_to_test = 50\n",
    "vectorizers = [TfidfVectorizer]\n",
    "n_recommendations_list = [5, 10,15]\n",
    "n_features_list = [1000,10000,100000]\n",
    "categories = ['skills', 'description']\n",
    "\n",
    "\n",
    "best_params_hitrate = {}\n",
    "best_params_f1 = {}\n",
    "\n",
    "# Initialize dictionaries to keep track of the highest scores for each n_recommendations\n",
    "highest_hitrate = {}\n",
    "highest_f1 = {}\n",
    "\n",
    "\n",
    "\n",
    "# Gridsearch\n",
    "# Test all combinations of parameters\n",
    "for n_recommendations in n_recommendations_list:\n",
    "    # Initialize the highest scores for this n_recommendations\n",
    "    highest_hitrate[n_recommendations] = 0\n",
    "    highest_f1[n_recommendations] = 0\n",
    "\n",
    "    for vectorizer in vectorizers:\n",
    "        for n_features in n_features_list:\n",
    "            for category in categories:\n",
    "                hitrate, f1 = evaluate_model(how_many_users_to_test, n_recommendations, vectorizer, n_features, category)\n",
    "\n",
    "                # Update the best parameters for hitrate\n",
    "                if hitrate > highest_hitrate[n_recommendations]:\n",
    "                    highest_hitrate[n_recommendations] = hitrate\n",
    "                    best_params_hitrate[n_recommendations] = (vectorizer, n_features, category)\n",
    "\n",
    "                # Update the best parameters for f1 score\n",
    "                if f1 > highest_f1[n_recommendations]:\n",
    "                    highest_f1[n_recommendations] = f1\n",
    "                    best_params_f1[n_recommendations] = (vectorizer, n_features, category)\n",
    "\n",
    "    # Print the best parameters for this n_recommendations\n",
    "    print(f\"For n_recommendations = {n_recommendations}:\")\n",
    "    print(f\"Hitrate: {highest_hitrate[n_recommendations]}, f1-score: {highest_f1[n_recommendations]}\")\n",
    "    print(f\"Best parameters for highest hitrate: Vectorizer = {best_params_hitrate[n_recommendations][0].__name__}, n_features = {best_params_hitrate[n_recommendations][1]}\")\n",
    "    print(f\"Best parameters for highest f1 score: Vectorizer = {best_params_f1[n_recommendations][0].__name__}, n_features = {best_params_f1[n_recommendations][1]}\")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
